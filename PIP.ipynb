{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedaahmed05/Quest-2/blob/main/PIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hmRwT7wZdrc"
      },
      "source": [
        "# MNIST Hand Written digit recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK9sn-97Zdrf"
      },
      "source": [
        "## Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abfHfDjjZdrf"
      },
      "outputs": [],
      "source": [
        "# Importing necessary packages\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Copmuter vision modules\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "H5DAygBBZs2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA_pD8UjZdrg"
      },
      "outputs": [],
      "source": [
        "#checking pytorch versions\n",
        "\n",
        "print(f'PyTorch version: {torch.__version__} \\ntorchvision version: {torchvision.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWYjg-HwZdri"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_uZvNlnZdrj"
      },
      "source": [
        "## MNIST Dataset\n",
        "\n",
        "Stands for Modified National Institure of Standards and Technology\n",
        "\n",
        "> * The data we will be working with has examples of handwritten digits (from 0 to 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX9bCgHXZdrj"
      },
      "outputs": [],
      "source": [
        "# Setup training data\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "                            root=\"data\", # where should we download the data to\n",
        "                            train = True, # Use data for training\n",
        "                            download =True, # Download data\n",
        "                            transform = ToTensor(), # Data is in PIL format we need tensors for training\n",
        "                            target_transform = None # for transforming labels\n",
        ")\n",
        "\n",
        "# Setup testing Data\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "                            root = \"data\",\n",
        "                            train = False,\n",
        "                            download = True,\n",
        "                            transform = ToTensor()\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cvkXKbpZdrk"
      },
      "outputs": [],
      "source": [
        "# Explore the data\n",
        "image, label = train_data[1]\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Image Shape ={image.shape}\\nLabel  = {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TJs0e5EZdrl"
      },
      "outputs": [],
      "source": [
        "# More about the values within these tensors\n",
        "max_value = image.max().item()\n",
        "\n",
        "min_value = image.min().item()\n",
        "\n",
        "print(f\"Max value: {max_value}\")\n",
        "print(f\"Min value: {min_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ZjnKLgZdrm"
      },
      "outputs": [],
      "source": [
        "# Example of the values within the tensor\n",
        "image[:,0,0], image[:,23,12]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5WEDtgeZdrn"
      },
      "outputs": [],
      "source": [
        "# How many samples do we have in the training and testing data\n",
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIwZ8ByDZdro"
      },
      "outputs": [],
      "source": [
        "# Classes within the dataset\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm4VSn1dZdrp"
      },
      "outputs": [],
      "source": [
        "# Plot one image from each class\n",
        "\n",
        "torch.manual_seed(12)\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "rows, cols = 2, 5  # Adjusted to fit 10 classes\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    for img, label in train_data:\n",
        "        if class_names[label] == class_name:\n",
        "            fig.add_subplot(rows, cols, i+1)\n",
        "            plt.title(class_name)\n",
        "            plt.axis(\"off\")\n",
        "            plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "            break\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WPtiotcZdrp"
      },
      "source": [
        "## Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmqOxRkYZdrq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Setup batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#Turn datasets into iterables\n",
        "\n",
        "train_dataloader = DataLoader(train_data, # turne training data into iterable\n",
        "                                batch_size = BATCH_SIZE, # set batch size\n",
        "                                shuffle = True # shuffle data)\n",
        "                                )\n",
        "\n",
        "test_dataloader = DataLoader(test_data, # turne testing data into iterable\n",
        "                                batch_size = BATCH_SIZE, # set batch size\n",
        "                                shuffle = False # shuffle data)\n",
        "                                )\n",
        "\n",
        "# Check the changes the made\n",
        "\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
        "\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of size {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1VjzscIZdrq"
      },
      "source": [
        "## Building a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hopatqtiZdrq"
      },
      "source": [
        "### Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPtYTIX5Zdrq"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "       super().__init__() #   Call the __init__ method of the parent class\n",
        "       self.layer_stack = nn.Sequential(\n",
        "           nn.Flatten(), # convert the input from 28x28 to 784 (Matrix to vector)\n",
        "           nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "           nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "       )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VdduKWBZdrr"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(12)\n",
        "\n",
        "# Define the input shape, hidden units, and output shape\n",
        "model_0 = SimpleModel(input_shape=28*28, # 28x28 image\n",
        "                        hidden_units=10, # No of neurons in the hidden layer\n",
        "                         output_shape=len(class_names)) # Output shape\n",
        "\n",
        "model_0.to(device) # Move the model to the GPU if available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRFfm3OqZdrr"
      },
      "source": [
        "### Importing metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkBvsa67Zdrr"
      },
      "outputs": [],
      "source": [
        "# Accuracy metric\n",
        "\n",
        "metric = torchmetrics.classification.Accuracy(task='multiclass',num_classes=len(class_names)).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNiJFjjaZdrr"
      },
      "outputs": [],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(12)\n",
        "\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training times)\n",
        "epochs = 5\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               epochs: int = 5,  # Default epochs\n",
        "               data_loader: torch.utils.data.DataLoader = train_dataloader,  # Default data loader\n",
        "               loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),  # Default loss function\n",
        "               optimizer: torch.optim.Optimizer = torch.optim.SGD, # Default optimizer class\n",
        "               learning_rate: int = 0.003, # keyword arguments to pass into optimizer instantiation.\n",
        "               accuracy_fn=metric,\n",
        "               device: torch.device = device):\n",
        "\n",
        "    # if optimizer is a class, instantiate with parameters from the model.\n",
        "    if isinstance(optimizer, type):\n",
        "        optimizer = optimizer(model.parameters(), learning_rate)\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f\"Epoch: {epoch}\\n-------\")\n",
        "        for batch, (X, y) in tqdm(enumerate(data_loader)):\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            train_loss += loss\n",
        "            acc = metric(y_pred,y) # Go from logits -> pred labels\n",
        "            acc = metric.compute()\n",
        "            train_acc += acc\n",
        "            metric.reset()\n",
        "\n",
        "            # 3. Optimizer zero grad\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 4. Loss backward\n",
        "            loss.backward()\n",
        "\n",
        "            # 5. Optimizer step\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate loss and accuracy per epoch and print out what's happening\n",
        "        train_loss /= len(data_loader)\n",
        "        train_acc /= len(data_loader)\n",
        "        print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "              accuracy_fn = metric,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            acc = metric(test_pred,y) # Go from logits -> pred labels\n",
        "            acc = metric.compute()\n",
        "            test_acc += acc\n",
        "            metric.reset()\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "Y6eEKboQhKCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D086SJkLZdrr"
      },
      "source": [
        "### Evaluvate model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5mJm87eZdrs"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(12)\n",
        "\n",
        "def eval_model(model:torch.nn.Module,\n",
        "                data_loader:torch.utils.data.DataLoader,\n",
        "                loss_fn:torch.nn.Module,\n",
        "                metric:torchmetrics.Metric):\n",
        "    \"\"\"\n",
        "        Returns a dictionary containing the results of model predicting on data_loader.\n",
        "\n",
        "        Args:\n",
        "            model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "            data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "            loss_fn (torch.nn.Module): The loss function of model.\n",
        "            accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "\n",
        "        Returns:\n",
        "            (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "\n",
        "    loss, acc =0, 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Setting tensors to device\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Making predictions\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Claculating loss\n",
        "            loss += loss_fn(y_pred, y)\n",
        "\n",
        "            # Calculating accuracy\n",
        "            acc += metric(y_pred, y)\n",
        "            metric.reset()\n",
        "\n",
        "        # Calculate average loss and accuracy\n",
        "        loss /= len(data_loader)\n",
        "        acc = acc / len(data_loader) * 100\n",
        "\n",
        "        return{\"Model_name\":model.__class__.__name__,\n",
        "                \"Loss\":loss,\n",
        "                \"Accuracy\":acc}\n",
        "\n",
        "# caluclate the evaluation metrics\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                            data_loader=test_dataloader,\n",
        "                            loss_fn= nn.CrossEntropyLoss(),\n",
        "                            metric=metric)\n",
        "\n",
        "model_0_results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAbUOEvPZdrs"
      },
      "source": [
        "## Build a model with non-linearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6r4fg3kZdrs"
      },
      "outputs": [],
      "source": [
        "class Model_1(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_layer_1: int, hidden_layer_2: int, output_shape: int)->None:\n",
        "      super().__init__()\n",
        "      self.layer_stack = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=input_shape,out_features=hidden_layer_1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_layer_1, out_features=hidden_layer_2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_layer_2, out_features=10),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs1Al4ztZdrs"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(12)\n",
        "\n",
        "model_1 = Model_1(input_shape=28*28,\n",
        "                     hidden_layer_1=10,\n",
        "                     hidden_layer_2=15,\n",
        "                     output_shape=len(class_names)\n",
        "                     ).to(device)\n",
        "\n",
        "#checking model 1\n",
        "next(model_1.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model=model_1,\n",
        "          epochs = 7,\n",
        "          data_loader= train_dataloader,\n",
        "          optimizer = torch.optim.Adam,\n",
        "          learning_rate=0.005,\n",
        "          accuracy_fn=metric,\n",
        "          device=device)"
      ],
      "metadata": {
        "id": "bBpySvU-py-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = eval_model(model=model_1,\n",
        "                            data_loader=test_dataloader,\n",
        "                            loss_fn= nn.CrossEntropyLoss(),\n",
        "                            metric=metric)\n",
        "\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "5W7Mz1aihMOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model with CNN"
      ],
      "metadata": {
        "id": "r-KyprO0r4nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network\n",
        "class CNN_module(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = CNN_module(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "model_2"
      ],
      "metadata": {
        "id": "cmDX5XUTezbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model"
      ],
      "metadata": {
        "id": "oNdRRzBNheWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model=model_2,\n",
        "          epochs = 7,\n",
        "          data_loader= train_dataloader,\n",
        "          optimizer = torch.optim.Adam,\n",
        "          learning_rate=0.003,\n",
        "          accuracy_fn=metric,\n",
        "          device=device)"
      ],
      "metadata": {
        "id": "s7HbrmfMheHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "jxu-KCFYjmaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model=model_2,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn= nn.CrossEntropyLoss(),\n",
        "            metric=metric)"
      ],
      "metadata": {
        "id": "gRMdSXOFjo9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn!!\n",
        "\n",
        "> Try to make the best model messing with the"
      ],
      "metadata": {
        "id": "mh3mMQNjVEeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model = model_0, # we have built 3 models so far, choose which one you would like to change\n",
        "               epochs = 5,  # Default epochs (Larger numbers might take more time)\n",
        "               data_loader= train_dataloader,\n",
        "               loss_fn =  nn.CrossEntropyLoss(),  # Default loss function\n",
        "               optimizer = torch.optim.SGD, # Default optimizer class\n",
        "               learning_rate =  0.003, # keyword arguments to pass into optimizer instantiation.\n",
        "               accuracy_fn=metric,\n",
        "               device = device):\n",
        "\n",
        "reslults = eval_model(model=model_0,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn= nn.CrossEntropyLoss(),\n",
        "            metric=metric)\n",
        "\n",
        "print(results)\n",
        "\n",
        "\"\"\"\n",
        "loss functions : https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "optimizers : https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cWWyR8YBVRhX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}